{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 画像のサイズを定義\n",
    "image_size = 224\n",
    "channels = 3  # 画像のチャンネル数 (RGB)\n",
    "\n",
    "# ダミーの画像データを生成\n",
    "batch_size = 64  # バッチサイズ\n",
    "input_data = torch.randn(batch_size, channels, image_size, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Inference Time: 0.3312 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from bitnetb158.models import bit_deit_base_patch16_224\n",
    "import time\n",
    "\n",
    "\n",
    "# モデルの読み込みとCUDAへの移行\n",
    "model = bit_deit_base_patch16_224(num_classes=1000)\n",
    "model.cuda(1)  # モデルをGPUに移行\n",
    "model.eval()  # 推論モードに切り替え\n",
    "\n",
    "# ダミーデータをGPUに移行\n",
    "input_data = input_data.cuda(1)\n",
    "\n",
    "# 推論時間を記録するリスト\n",
    "inference_times = []\n",
    "\n",
    "# 複数回の推論を実行して推論時間を計測\n",
    "num_trials = 10  # 試行回数\n",
    "for _ in range(num_trials):\n",
    "    # タイマーの開始\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 推論の実行\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data)\n",
    "\n",
    "    # CUDAの同期\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # タイマーの終了\n",
    "    end_time = time.time()\n",
    "\n",
    "    # 推論時間の計算（秒単位）および記録\n",
    "    inference_time = end_time - start_time\n",
    "    inference_times.append(inference_time)\n",
    "\n",
    "# 平均推論時間の計算\n",
    "average_inference_time = sum(inference_times) / num_trials\n",
    "print(\"Average Inference Time: {:.4f} seconds\".format(average_inference_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Inference Time: 0.2362 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from bitnetb158.models import bit_deit_base_patch16_224\n",
    "import time\n",
    "from bitnetb158 import convert_weights_to_packed\n",
    "from bitnetb158.nn import BitLinearb158\n",
    "\n",
    "# モデルの読み込みとCUDAへの移行\n",
    "model = bit_deit_base_patch16_224(num_classes=1000)\n",
    "convert_weights_to_packed(model, BitLinearb158)\n",
    "torch.save(model.state_dict(), \"packed_weights.pth\")\n",
    "model.cuda(1)  # モデルをGPUに移行\n",
    "model.eval()  # 推論モードに切り替え\n",
    "\n",
    "# ダミーデータをGPUに移行\n",
    "input_data = input_data.cuda(1)\n",
    "\n",
    "# 推論時間を記録するリスト\n",
    "inference_times = []\n",
    "\n",
    "# 複数回の推論を実行して推論時間を計測\n",
    "num_trials = 10  # 試行回数\n",
    "for _ in range(num_trials):\n",
    "    # タイマーの開始\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 推論の実行\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data)\n",
    "\n",
    "    # CUDAの同期\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # タイマーの終了\n",
    "    end_time = time.time()\n",
    "\n",
    "    # 推論時間の計算（秒単位）および記録\n",
    "    inference_time = end_time - start_time\n",
    "    inference_times.append(inference_time)\n",
    "\n",
    "# 平均推論時間の計算\n",
    "average_inference_time = sum(inference_times) / num_trials\n",
    "print(\"Average Inference Time: {:.4f} seconds\".format(average_inference_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5700934579439252"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.22 / 2.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
